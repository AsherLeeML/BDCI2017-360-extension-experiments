{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:02.250793Z",
     "start_time": "2018-07-31T01:38:58.069931Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep/pythonenv/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Building prefix dict from the default dictionary ...\n",
      "2018-07-31 09:38:59 AM:DEBUG:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "2018-07-31 09:38:59 AM:DEBUG:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.587 seconds.\n",
      "2018-07-31 09:38:59 AM:DEBUG:Loading model cost 0.587 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2018-07-31 09:38:59 AM:DEBUG:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from WVutils.data import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from datautils.other import *\n",
    "from models.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:02.578899Z",
     "start_time": "2018-07-31T01:39:02.280680Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:02.625137Z",
     "start_time": "2018-07-31T01:39:02.608608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:05.351565Z",
     "start_time": "2018-07-31T01:39:02.734644Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(Config.cache_path + 'trainset.csv', sep='\\t')\n",
    "val = pd.read_csv(Config.cache_path + 'valset.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:05.555983Z",
     "start_time": "2018-07-31T01:39:05.541945Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "val_label = to_categorical(val.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:40:19.503605Z",
     "start_time": "2018-07-31T01:40:19.405065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.fillna(\"\", inplace=True)\n",
    "val.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:34.990998Z",
     "start_time": "2018-07-30T14:27:32.354204Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    }
   ],
   "source": [
    "from datautils.pre import *\n",
    "from WVutils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:39.369148Z",
     "start_time": "2018-07-30T14:27:39.354443Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "model_name='textcnn'\n",
    "train_batch_generator = word_cnn_train_batch_generator\n",
    "print('Loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:40.621065Z",
     "start_time": "2018-07-30T14:27:40.578995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_word_seq = pickle.load(open(Config.cache_path + 'val_cnn_seq.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:42.600111Z",
     "start_time": "2018-07-30T14:27:42.450204Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_embed_weight = np.load(Config.word_embed_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:45.104978Z",
     "start_time": "2018-07-30T14:27:43.961771Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model=get_textcnn(Config.word_seq_maxlen, word_embed_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T12:57:32.877670Z",
     "start_time": "2018-07-30T12:57:32.856703Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_word_seq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:28.893328Z",
     "start_time": "2018-07-30T14:28:28.873985Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1000, 256)    60197376    input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 1000, 256)    65792       embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 256)    1024        time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1000, 256)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 998, 256)     196864      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 997, 256)     262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 996, 256)     327936      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 998, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 997, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 996, 256)     1024        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 998, 256)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 997, 256)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 996, 256)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 256)          0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 256)          0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 256)          0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_feat (Concatenate)         (None, 768)          0           global_max_pooling1d_22[0][0]    \n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 768)          0           conv_feat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          196864      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 256)          1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 256)          0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            514         activation_40[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 61,252,866\n",
      "Trainable params: 61,250,306\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:13:51.246636Z",
     "start_time": "2018-07-30T13:54:32.670496Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 186s 120ms/step - loss: 0.6724 - acc: 0.6077 - val_loss: 0.6296 - val_acc: 0.6320\n",
      "0.7739130434782608 0.0827906976744186 0.14957983193277308\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 187s 121ms/step - loss: 0.5640 - acc: 0.6880 - val_loss: 0.6103 - val_acc: 0.6475\n",
      "0.5284925232385828 0.9123255813953488 0.6692826068412523\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 190s 123ms/step - loss: 0.4974 - acc: 0.7393 - val_loss: 0.4744 - val_acc: 0.7565\n",
      "0.6551790158912503 0.7958139534883721 0.7186810878924709\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 189s 122ms/step - loss: 0.4356 - acc: 0.7834 - val_loss: 0.4295 - val_acc: 0.7910\n",
      "0.7162308191052518 0.7706976744186047 0.7424666741346477\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 187s 121ms/step - loss: 0.4038 - acc: 0.8023 - val_loss: 0.4211 - val_acc: 0.7989\n",
      "0.7579051383399209 0.7134883720930233 0.7350263536176328\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 188s 122ms/step - loss: 0.3818 - acc: 0.8171 - val_loss: 0.4272 - val_acc: 0.7875\n",
      "0.6863489652553636 0.8406976744186047 0.7557227971150831\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: word_embedding",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-93748201a414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n\u001b[1;32m      8\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenv/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: word_embedding"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    if i == 3:\n",
    "        K.set_value(model.optimizer.lr, 0.0002)\n",
    "    if i == 6:\n",
    "        for l in trainable_layer:\n",
    "            model.get_layer(l).trainable = True\n",
    "    model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:06.323496Z",
     "start_time": "2018-07-30T14:27:04.618660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save(Config.cache_path+'txtcnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:26.374809Z",
     "start_time": "2018-07-30T14:28:23.994675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = load_model(Config.cache_path+'txtcnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:34.469363Z",
     "start_time": "2018-07-30T14:28:33.673759Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:38:32.859464Z",
     "start_time": "2018-07-30T14:28:48.860468Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 189s 122ms/step - loss: 0.2883 - acc: 0.8695 - val_loss: 0.4127 - val_acc: 0.8065\n",
      "0.7214518760195758 0.8227906976744186 0.7687961755758366\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 191s 124ms/step - loss: 0.2562 - acc: 0.8875 - val_loss: 0.4350 - val_acc: 0.8002\n",
      "0.7036821705426357 0.8444186046511628 0.7676532769556025\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 189s 122ms/step - loss: 0.2297 - acc: 0.9006 - val_loss: 0.5594 - val_acc: 0.7690\n",
      "0.6450123660346249 0.9097674418604651 0.754848046309696\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:45.553128Z",
     "start_time": "2018-07-30T14:28:45.450829Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 601\n",
      "nan 3373\n",
      "nan 21249\n",
      "nan 25593\n",
      "nan 31465\n",
      "nan 32237\n",
      "nan 34887\n",
      "nan 45295\n",
      "nan 50265\n",
      "nan 57035\n",
      "nan 57351\n",
      "nan 60613\n",
      "nan 74078\n",
      "nan 95445\n",
      "nan 97726\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for content in train.content.values:\n",
    "    if type(content) != str:\n",
    "        print(content, i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:47.838202Z",
     "start_time": "2018-07-30T14:28:47.785949Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:40:53.881451Z",
     "start_time": "2018-07-30T13:39:35.689Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# No TimeDistributed layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:46:50.298617Z",
     "start_time": "2018-07-30T14:46:48.691140Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_noTD=get_textcnn_no_TD(Config.word_seq_maxlen, word_embed_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T15:05:31.858909Z",
     "start_time": "2018-07-30T14:46:51.874932Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 183s 119ms/step - loss: 0.6780 - acc: 0.6060 - val_loss: 0.6437 - val_acc: 0.6319\n",
      "0.7687366167023555 0.08348837209302326 0.15061883784350746\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 181s 117ms/step - loss: 0.6143 - acc: 0.6537 - val_loss: 0.5501 - val_acc: 0.6862\n",
      "0.7892223738062756 0.26906976744186045 0.4013180714533472\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 183s 118ms/step - loss: 0.5475 - acc: 0.7036 - val_loss: 0.5002 - val_acc: 0.7364\n",
      "0.6674641148325359 0.6488372093023256 0.6580188679245284\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 181s 117ms/step - loss: 0.4800 - acc: 0.7560 - val_loss: 0.4926 - val_acc: 0.7437\n",
      "0.6343188826410303 0.8132558139534883 0.7127280138591664\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 183s 119ms/step - loss: 0.4484 - acc: 0.7768 - val_loss: 0.4870 - val_acc: 0.7418\n",
      "0.6297085998578535 0.8241860465116279 0.7139403706688153\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 181s 117ms/step - loss: 0.4248 - acc: 0.7934 - val_loss: 0.4653 - val_acc: 0.7609\n",
      "0.6693711967545639 0.7674418604651163 0.715059588299025\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainable_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-be41d0f179f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_noTD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mmodel_noTD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     model_noTD.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainable_layer' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    if i == 3:\n",
    "        K.set_value(model_noTD.optimizer.lr, 0.0002)\n",
    "    if i == 6:\n",
    "        for l in trainable_layer:\n",
    "            model_noTD.get_layer(l).trainable = True\n",
    "    model_noTD.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_noTD.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T00:58:12.462472Z",
     "start_time": "2018-07-31T00:58:12.448208Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in model_noTD.layers:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:07:48.336575Z",
     "start_time": "2018-07-31T00:58:34.711681Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 174s 113ms/step - loss: 0.4031 - acc: 0.8079 - val_loss: 0.4534 - val_acc: 0.7737\n",
      "0.6968050423820908 0.7455813953488372 0.7203684979215819\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 184s 119ms/step - loss: 0.3771 - acc: 0.8243 - val_loss: 0.4546 - val_acc: 0.7693\n",
      "0.6789195775792038 0.7774418604651163 0.7248482220294883\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 182s 118ms/step - loss: 0.3592 - acc: 0.8331 - val_loss: 0.4750 - val_acc: 0.7555\n",
      "0.6444205238607822 0.8353488372093023 0.7275673485922624\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model_noTD.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_noTD.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:05.876594Z",
     "start_time": "2018-07-31T01:39:05.748381Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_word_seq = pickle.load(open(Config.cache_path+'val_han_seq.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:13:25.767479Z",
     "start_time": "2018-07-31T01:13:25.731302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?get_han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:08.745843Z",
     "start_time": "2018-07-31T01:39:06.082394Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datautils.pre import *\n",
    "from WVutils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:09.427266Z",
     "start_time": "2018-07-31T01:39:09.412240Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_generator = word_han_train_batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:10.091149Z",
     "start_time": "2018-07-31T01:39:10.076904Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:10.882776Z",
     "start_time": "2018-07-31T01:39:10.737915Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_seq = val_word_seq\n",
    "word_embed_weight = np.load(Config.word_embed_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:40:24.339963Z",
     "start_time": "2018-07-31T01:40:22.532824Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 45, 48)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 45, 256)           60493360  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 45, 256)           295680    \n",
      "_________________________________________________________________\n",
      "attention_4 (Attention)      (None, 256)               301       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 60,856,671\n",
      "Trainable params: 658,783\n",
      "Non-trainable params: 60,197,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_han=get_han(Config.sentence_num, Config.sentence_word_length, word_embed_weight)\n",
    "model_han.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T02:34:31.741746Z",
     "start_time": "2018-07-31T01:40:28.126308Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 305s 197ms/step - loss: 0.6407 - acc: 0.6338 - val_loss: 0.5842 - val_acc: 0.6782\n",
      "0.6360057265569077 0.41325581395348837 0.5009867493656611\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 313s 203ms/step - loss: 0.5448 - acc: 0.7062 - val_loss: 0.5670 - val_acc: 0.7059\n",
      "0.6650139448404091 0.4990697674418605 0.5702138966387672\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 318s 206ms/step - loss: 0.4807 - acc: 0.7533 - val_loss: 0.5204 - val_acc: 0.7372\n",
      "0.6614714645885859 0.6711627906976744 0.6662818884912848\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 312s 202ms/step - loss: 0.3717 - acc: 0.8240 - val_loss: 0.5002 - val_acc: 0.7635\n",
      "0.6919077757685352 0.7118604651162791 0.7017423200366805\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 311s 201ms/step - loss: 0.3157 - acc: 0.8539 - val_loss: 0.5552 - val_acc: 0.7488\n",
      "0.6536078352988207 0.7604651162790698 0.7029990325701387\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 313s 202ms/step - loss: 0.2709 - acc: 0.8785 - val_loss: 0.6027 - val_acc: 0.7569\n",
      "0.7206840390879479 0.6174418604651163 0.6650801603206412\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 314s 203ms/step - loss: 0.2291 - acc: 0.8995 - val_loss: 0.6253 - val_acc: 0.7541\n",
      "0.6653535144101181 0.7462790697674418 0.7034966568014906\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 315s 204ms/step - loss: 0.1901 - acc: 0.9196 - val_loss: 0.7307 - val_acc: 0.7530\n",
      "0.6570748164318317 0.77 0.7090694935217904\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 317s 205ms/step - loss: 0.1556 - acc: 0.9356 - val_loss: 0.8546 - val_acc: 0.7604\n",
      "0.7053307008884502 0.6646511627906977 0.6843869731800767\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 314s 203ms/step - loss: 0.1273 - acc: 0.9491 - val_loss: 0.9301 - val_acc: 0.7551\n",
      "0.6747171453437772 0.7211627906976744 0.6971672661870503\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i == 3:\n",
    "        K.set_value(model_han.optimizer.lr, 0.0002)\n",
    "    if i == 7:\n",
    "        for l in model_han.layers:\n",
    "            l.trainable = True\n",
    "    model_han.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_han.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# HCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T02:40:15.020758Z",
     "start_time": "2018-07-31T02:40:12.881719Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 45, 48)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 45, 256)      60493360    input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 43, 256)      196864      time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 42, 256)      262400      time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 41, 256)      327936      time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 43, 256)      1024        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 42, 256)      1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 256)      1024        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 43, 256)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 42, 256)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 41, 256)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 256)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 256)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 256)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_feat (Concatenate)         (None, 768)          0           global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           conv_feat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          196864      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256)          1024        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            514         activation_10[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 61,482,034\n",
      "Trainable params: 1,282,610\n",
      "Non-trainable params: 60,199,424\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_batch_generator = word_han_train_batch_generator\n",
    "model_hcnn = get_hcnn(Config.sentence_num, Config.sentence_word_length, word_embed_weight)\n",
    "model_hcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T03:35:42.495343Z",
     "start_time": "2018-07-31T02:45:06.930483Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 289s 187ms/step - loss: 0.6691 - acc: 0.6080 - val_loss: 0.6429 - val_acc: 0.6425\n",
      "0.7050279329608938 0.14674418604651163 0.24292589027911451\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 293s 190ms/step - loss: 0.5747 - acc: 0.6812 - val_loss: 0.5589 - val_acc: 0.6963\n",
      "0.6070073644275831 0.6325581395348837 0.6195194169229018\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.5211 - acc: 0.7217 - val_loss: 0.5273 - val_acc: 0.7190\n",
      "0.661847389558233 0.5748837209302325 0.6153080273802116\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 294s 190ms/step - loss: 0.4725 - acc: 0.7582 - val_loss: 0.5174 - val_acc: 0.7307\n",
      "0.6832876712328767 0.58 0.6274213836477988\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 294s 190ms/step - loss: 0.4168 - acc: 0.7962 - val_loss: 0.6147 - val_acc: 0.7117\n",
      "0.8130892956184138 0.34093023255813953 0.4804194658364739\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.2997 - acc: 0.8656 - val_loss: 0.5536 - val_acc: 0.7540\n",
      "0.6885944155229532 0.6767441860465117 0.6826178747361014\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 294s 190ms/step - loss: 0.2517 - acc: 0.8898 - val_loss: 0.5906 - val_acc: 0.7549\n",
      "0.6934394597202123 0.6686046511627907 0.6807956429078854\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 296s 191ms/step - loss: 0.2187 - acc: 0.9061 - val_loss: 0.6309 - val_acc: 0.7524\n",
      "0.6806510774873911 0.6904651162790698 0.6855229739090279\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 296s 191ms/step - loss: 0.1915 - acc: 0.9188 - val_loss: 0.7069 - val_acc: 0.7519\n",
      "0.6925717087521451 0.6569767441860465 0.6743048096431554\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 296s 191ms/step - loss: 0.1673 - acc: 0.9304 - val_loss: 0.7542 - val_acc: 0.7499\n",
      "0.6686261702590899 0.7141860465116279 0.6906555717980434\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        K.set_value(model_hcnn.optimizer.lr, 0.0001)\n",
    "    if i == 8:\n",
    "        for l in model_hcnn.layers:\n",
    "            l.trainable = True\n",
    "    model_hcnn.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_hcnn.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch to SPcut embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T03:35:43.291541Z",
     "start_time": "2018-07-31T03:35:43.190290Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_word_embed_weight = np.load(Config.word_embed_weight_path_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T03:40:52.494161Z",
     "start_time": "2018-07-31T03:40:52.452698Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_word_seq = pickle.load(open(Config.cache_path + 'val_cnn_seq.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T03:40:54.162095Z",
     "start_time": "2018-07-31T03:40:54.146875Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_generator = word_cnn_train_batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T04:12:36.014140Z",
     "start_time": "2018-07-31T03:40:54.885939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 182s 118ms/step - loss: 0.6823 - acc: 0.6051 - val_loss: 0.6635 - val_acc: 0.6236\n",
      "0.5531914893617021 0.19348837209302325 0.2866988283942109\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 185s 120ms/step - loss: 0.6292 - acc: 0.6397 - val_loss: 0.5911 - val_acc: 0.6514\n",
      "0.7859778597785978 0.1486046511627907 0.2499511050264033\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 186s 120ms/step - loss: 0.5728 - acc: 0.6752 - val_loss: 0.5642 - val_acc: 0.6688\n",
      "0.8249258160237388 0.19395348837209303 0.3140651478064395\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 185s 120ms/step - loss: 0.5447 - acc: 0.6959 - val_loss: 0.5298 - val_acc: 0.7149\n",
      "0.6313176895306859 0.6506976744186046 0.640861200183234\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 186s 120ms/step - loss: 0.5082 - acc: 0.7259 - val_loss: 0.5142 - val_acc: 0.7265\n",
      "0.6482885366413967 0.6562790697674419 0.6522593320235756\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 186s 121ms/step - loss: 0.4934 - acc: 0.7388 - val_loss: 0.5131 - val_acc: 0.7243\n",
      "0.633452706972825 0.6993023255813954 0.6647507461036808\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 185s 119ms/step - loss: 0.4814 - acc: 0.7496 - val_loss: 0.5077 - val_acc: 0.7264\n",
      "0.6329348722176422 0.7141860465116279 0.6711101398601399\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 186s 120ms/step - loss: 0.4701 - acc: 0.7566 - val_loss: 0.5016 - val_acc: 0.7325\n",
      "0.657321594068582 0.6597674418604651 0.6585422469823584\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 185s 120ms/step - loss: 0.4598 - acc: 0.7637 - val_loss: 0.5018 - val_acc: 0.7318\n",
      "0.6469307792773182 0.6911627906976744 0.6683157184618844\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 184s 119ms/step - loss: 0.4507 - acc: 0.7722 - val_loss: 0.5022 - val_acc: 0.7327\n",
      "0.6413721413721414 0.7174418604651163 0.677277716794731\n"
     ]
    }
   ],
   "source": [
    "model=get_textcnn(Config.word_seq_maxlen, sp_word_embed_weight)\n",
    "for i in range(10):\n",
    "    if i == 4:\n",
    "        K.set_value(model.optimizer.lr, 0.0001)\n",
    "    if i == 7:\n",
    "        for l in model.layers:\n",
    "            l.trainable = True\n",
    "    model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T05:06:52.772486Z",
     "start_time": "2018-07-31T04:12:36.723926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 315s 204ms/step - loss: 0.6271 - acc: 0.6433 - val_loss: 0.6980 - val_acc: 0.6212\n",
      "0.5097722263041881 0.8067441860465117 0.624763619990995\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 313s 202ms/step - loss: 0.5361 - acc: 0.7132 - val_loss: 0.5383 - val_acc: 0.7244\n",
      "0.6739846322722283 0.5711627906976744 0.6183282980866063\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 313s 203ms/step - loss: 0.4754 - acc: 0.7588 - val_loss: 0.4998 - val_acc: 0.7395\n",
      "0.652692062140881 0.7132558139534884 0.6816312923658184\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 313s 202ms/step - loss: 0.4144 - acc: 0.7983 - val_loss: 0.4800 - val_acc: 0.7604\n",
      "0.674496644295302 0.747906976744186 0.7093074547860609\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 315s 204ms/step - loss: 0.3506 - acc: 0.8364 - val_loss: 0.5163 - val_acc: 0.7688\n",
      "0.8134141990724224 0.5302325581395348 0.6419822610164719\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 315s 204ms/step - loss: 0.2298 - acc: 0.9022 - val_loss: 0.5224 - val_acc: 0.7887\n",
      "0.7319248826291079 0.7251162790697674 0.7285046728971961\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 317s 205ms/step - loss: 0.1831 - acc: 0.9243 - val_loss: 0.5850 - val_acc: 0.7825\n",
      "0.7154802259887005 0.7362790697674418 0.7257306590257879\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 315s 204ms/step - loss: 0.1527 - acc: 0.9392 - val_loss: 0.6567 - val_acc: 0.7825\n",
      "0.7253188474256023 0.7141860465116279 0.7197093977033043\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 311s 201ms/step - loss: 0.1263 - acc: 0.9510 - val_loss: 0.7498 - val_acc: 0.7801\n",
      "0.7228144989339019 0.7095348837209302 0.7161131322614718\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 314s 203ms/step - loss: 0.1026 - acc: 0.9621 - val_loss: 0.8646 - val_acc: 0.7782\n",
      "0.7279411764705882 0.6906976744186046 0.7088305489260143\n"
     ]
    }
   ],
   "source": [
    "val_word_seq = pickle.load(open(Config.cache_path+'val_han_seq.pkl', \"rb\"))\n",
    "train_batch_generator = word_han_train_batch_generator\n",
    "model_han=get_han(Config.sentence_num, Config.sentence_word_length, word_embed_weight)\n",
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        K.set_value(model_han.optimizer.lr, 0.0001)\n",
    "    if i == 8:\n",
    "        for l in model_han.layers:\n",
    "            l.trainable = True\n",
    "    model_han.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_han.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:38:19.966888Z",
     "start_time": "2018-07-31T06:47:35.970561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 290s 188ms/step - loss: 0.6709 - acc: 0.6071 - val_loss: 0.6386 - val_acc: 0.6341\n",
      "0.5439156818907698 0.396046511627907 0.4583501547570986\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.5823 - acc: 0.6779 - val_loss: 0.5977 - val_acc: 0.6588\n",
      "0.5446676465784746 0.7755813953488372 0.6399309219994243\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.5297 - acc: 0.7189 - val_loss: 0.5373 - val_acc: 0.7120\n",
      "0.6155102040816327 0.7013953488372093 0.6556521739130435\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 296s 192ms/step - loss: 0.4678 - acc: 0.7616 - val_loss: 0.5001 - val_acc: 0.7393\n",
      "0.6479950392724266 0.7290697674418605 0.6861457649376231\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.3944 - acc: 0.8113 - val_loss: 0.4725 - val_acc: 0.7629\n",
      "0.6628175519630485 0.8009302325581396 0.725358045492839\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.2745 - acc: 0.8808 - val_loss: 0.4953 - val_acc: 0.7843\n",
      "0.730117028898973 0.7109302325581396 0.72039589961117\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.2310 - acc: 0.9000 - val_loss: 0.5400 - val_acc: 0.7794\n",
      "0.7040749618653301 0.7513953488372093 0.7269659129260884\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.2013 - acc: 0.9146 - val_loss: 0.5777 - val_acc: 0.7828\n",
      "0.7212317666126418 0.7244186046511628 0.7228216730479173\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.1749 - acc: 0.9276 - val_loss: 0.6342 - val_acc: 0.7788\n",
      "0.7305507532724129 0.687906976744186 0.7085878548329142\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 295s 191ms/step - loss: 0.1533 - acc: 0.9369 - val_loss: 0.6804 - val_acc: 0.7776\n",
      "0.7215583173996176 0.7020930232558139 0.7116925978312116\n"
     ]
    }
   ],
   "source": [
    "model_hcnn = get_hcnn(Config.sentence_num, Config.sentence_word_length, word_embed_weight)\n",
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        K.set_value(model_hcnn.optimizer.lr, 0.0001)\n",
    "    if i == 8:\n",
    "        for l in model_hcnn.layers:\n",
    "            l.trainable = True\n",
    "    model_hcnn.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_hcnn.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 592,
   "position": {
    "height": "40px",
    "left": "1548px",
    "right": "20px",
    "top": "120px",
    "width": "352px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
