{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:02.250793Z",
     "start_time": "2018-07-31T01:38:58.069931Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep/pythonenv/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Building prefix dict from the default dictionary ...\n",
      "2018-07-31 09:38:59 AM:DEBUG:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "2018-07-31 09:38:59 AM:DEBUG:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.587 seconds.\n",
      "2018-07-31 09:38:59 AM:DEBUG:Loading model cost 0.587 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2018-07-31 09:38:59 AM:DEBUG:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from WVutils.data import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from datautils.other import *\n",
    "from models.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:02.578899Z",
     "start_time": "2018-07-31T01:39:02.280680Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:02.625137Z",
     "start_time": "2018-07-31T01:39:02.608608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:05.351565Z",
     "start_time": "2018-07-31T01:39:02.734644Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(Config.cache_path + 'trainset.csv', sep='\\t')\n",
    "val = pd.read_csv(Config.cache_path + 'valset.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:05.555983Z",
     "start_time": "2018-07-31T01:39:05.541945Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "val_label = to_categorical(val.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:40:19.503605Z",
     "start_time": "2018-07-31T01:40:19.405065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.fillna(\"\", inplace=True)\n",
    "val.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:34.990998Z",
     "start_time": "2018-07-30T14:27:32.354204Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/deep/pythonenv/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    }
   ],
   "source": [
    "from datautils.pre import *\n",
    "from WVutils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:39.369148Z",
     "start_time": "2018-07-30T14:27:39.354443Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "model_name='textcnn'\n",
    "train_batch_generator = word_cnn_train_batch_generator\n",
    "print('Loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:40.621065Z",
     "start_time": "2018-07-30T14:27:40.578995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_word_seq = pickle.load(open(Config.cache_path + 'val_cnn_seq.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:42.600111Z",
     "start_time": "2018-07-30T14:27:42.450204Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_embed_weight = np.load(Config.word_embed_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:45.104978Z",
     "start_time": "2018-07-30T14:27:43.961771Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model=get_textcnn(Config.word_seq_maxlen, word_embed_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T12:57:32.877670Z",
     "start_time": "2018-07-30T12:57:32.856703Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_word_seq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:28.893328Z",
     "start_time": "2018-07-30T14:28:28.873985Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1000, 256)    60197376    input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 1000, 256)    65792       embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 256)    1024        time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1000, 256)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 998, 256)     196864      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 997, 256)     262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 996, 256)     327936      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 998, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 997, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 996, 256)     1024        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 998, 256)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 997, 256)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 996, 256)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 256)          0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 256)          0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 256)          0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_feat (Concatenate)         (None, 768)          0           global_max_pooling1d_22[0][0]    \n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 768)          0           conv_feat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          196864      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 256)          1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 256)          0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            514         activation_40[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 61,252,866\n",
      "Trainable params: 61,250,306\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:13:51.246636Z",
     "start_time": "2018-07-30T13:54:32.670496Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 186s 120ms/step - loss: 0.6724 - acc: 0.6077 - val_loss: 0.6296 - val_acc: 0.6320\n",
      "0.7739130434782608 0.0827906976744186 0.14957983193277308\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 187s 121ms/step - loss: 0.5640 - acc: 0.6880 - val_loss: 0.6103 - val_acc: 0.6475\n",
      "0.5284925232385828 0.9123255813953488 0.6692826068412523\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 190s 123ms/step - loss: 0.4974 - acc: 0.7393 - val_loss: 0.4744 - val_acc: 0.7565\n",
      "0.6551790158912503 0.7958139534883721 0.7186810878924709\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 189s 122ms/step - loss: 0.4356 - acc: 0.7834 - val_loss: 0.4295 - val_acc: 0.7910\n",
      "0.7162308191052518 0.7706976744186047 0.7424666741346477\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 187s 121ms/step - loss: 0.4038 - acc: 0.8023 - val_loss: 0.4211 - val_acc: 0.7989\n",
      "0.7579051383399209 0.7134883720930233 0.7350263536176328\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 188s 122ms/step - loss: 0.3818 - acc: 0.8171 - val_loss: 0.4272 - val_acc: 0.7875\n",
      "0.6863489652553636 0.8406976744186047 0.7557227971150831\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: word_embedding",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-93748201a414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n\u001b[1;32m      8\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenv/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: word_embedding"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    if i == 3:\n",
    "        K.set_value(model.optimizer.lr, 0.0002)\n",
    "    if i == 6:\n",
    "        for l in trainable_layer:\n",
    "            model.get_layer(l).trainable = True\n",
    "    model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:27:06.323496Z",
     "start_time": "2018-07-30T14:27:04.618660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save(Config.cache_path+'txtcnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:26.374809Z",
     "start_time": "2018-07-30T14:28:23.994675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = load_model(Config.cache_path+'txtcnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:34.469363Z",
     "start_time": "2018-07-30T14:28:33.673759Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:38:32.859464Z",
     "start_time": "2018-07-30T14:28:48.860468Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 189s 122ms/step - loss: 0.2883 - acc: 0.8695 - val_loss: 0.4127 - val_acc: 0.8065\n",
      "0.7214518760195758 0.8227906976744186 0.7687961755758366\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 191s 124ms/step - loss: 0.2562 - acc: 0.8875 - val_loss: 0.4350 - val_acc: 0.8002\n",
      "0.7036821705426357 0.8444186046511628 0.7676532769556025\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 189s 122ms/step - loss: 0.2297 - acc: 0.9006 - val_loss: 0.5594 - val_acc: 0.7690\n",
      "0.6450123660346249 0.9097674418604651 0.754848046309696\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:45.553128Z",
     "start_time": "2018-07-30T14:28:45.450829Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 601\n",
      "nan 3373\n",
      "nan 21249\n",
      "nan 25593\n",
      "nan 31465\n",
      "nan 32237\n",
      "nan 34887\n",
      "nan 45295\n",
      "nan 50265\n",
      "nan 57035\n",
      "nan 57351\n",
      "nan 60613\n",
      "nan 74078\n",
      "nan 95445\n",
      "nan 97726\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for content in train.content.values:\n",
    "    if type(content) != str:\n",
    "        print(content, i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:28:47.838202Z",
     "start_time": "2018-07-30T14:28:47.785949Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:40:53.881451Z",
     "start_time": "2018-07-30T13:39:35.689Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# No TimeDistributed layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:46:50.298617Z",
     "start_time": "2018-07-30T14:46:48.691140Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_noTD=get_textcnn_no_TD(Config.word_seq_maxlen, word_embed_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T15:05:31.858909Z",
     "start_time": "2018-07-30T14:46:51.874932Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 183s 119ms/step - loss: 0.6780 - acc: 0.6060 - val_loss: 0.6437 - val_acc: 0.6319\n",
      "0.7687366167023555 0.08348837209302326 0.15061883784350746\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 181s 117ms/step - loss: 0.6143 - acc: 0.6537 - val_loss: 0.5501 - val_acc: 0.6862\n",
      "0.7892223738062756 0.26906976744186045 0.4013180714533472\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 183s 118ms/step - loss: 0.5475 - acc: 0.7036 - val_loss: 0.5002 - val_acc: 0.7364\n",
      "0.6674641148325359 0.6488372093023256 0.6580188679245284\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 181s 117ms/step - loss: 0.4800 - acc: 0.7560 - val_loss: 0.4926 - val_acc: 0.7437\n",
      "0.6343188826410303 0.8132558139534883 0.7127280138591664\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 183s 119ms/step - loss: 0.4484 - acc: 0.7768 - val_loss: 0.4870 - val_acc: 0.7418\n",
      "0.6297085998578535 0.8241860465116279 0.7139403706688153\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 181s 117ms/step - loss: 0.4248 - acc: 0.7934 - val_loss: 0.4653 - val_acc: 0.7609\n",
      "0.6693711967545639 0.7674418604651163 0.715059588299025\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainable_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-be41d0f179f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_noTD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mmodel_noTD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     model_noTD.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainable_layer' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    if i == 3:\n",
    "        K.set_value(model_noTD.optimizer.lr, 0.0002)\n",
    "    if i == 6:\n",
    "        for l in trainable_layer:\n",
    "            model_noTD.get_layer(l).trainable = True\n",
    "    model_noTD.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_noTD.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T00:58:12.462472Z",
     "start_time": "2018-07-31T00:58:12.448208Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in model_noTD.layers:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:07:48.336575Z",
     "start_time": "2018-07-31T00:58:34.711681Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 174s 113ms/step - loss: 0.4031 - acc: 0.8079 - val_loss: 0.4534 - val_acc: 0.7737\n",
      "0.6968050423820908 0.7455813953488372 0.7203684979215819\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 184s 119ms/step - loss: 0.3771 - acc: 0.8243 - val_loss: 0.4546 - val_acc: 0.7693\n",
      "0.6789195775792038 0.7774418604651163 0.7248482220294883\n",
      "Epoch 1/1\n",
      "1546/1546 [==============================] - 182s 118ms/step - loss: 0.3592 - acc: 0.8331 - val_loss: 0.4750 - val_acc: 0.7555\n",
      "0.6444205238607822 0.8353488372093023 0.7275673485922624\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model_noTD.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_noTD.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:05.876594Z",
     "start_time": "2018-07-31T01:39:05.748381Z"
    }
   },
   "outputs": [],
   "source": [
    "val_word_seq = pickle.load(open(Config.cache_path+'val_han_seq.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:13:25.767479Z",
     "start_time": "2018-07-31T01:13:25.731302Z"
    }
   },
   "outputs": [],
   "source": [
    "?get_han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:08.745843Z",
     "start_time": "2018-07-31T01:39:06.082394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datautils.pre import *\n",
    "from WVutils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:09.427266Z",
     "start_time": "2018-07-31T01:39:09.412240Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_generator = word_han_train_batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:10.091149Z",
     "start_time": "2018-07-31T01:39:10.076904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:39:10.882776Z",
     "start_time": "2018-07-31T01:39:10.737915Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_seq = val_word_seq\n",
    "word_embed_weight = np.load(Config.word_embed_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:40:24.339963Z",
     "start_time": "2018-07-31T01:40:22.532824Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 45, 48)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 45, 256)           60493360  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 45, 256)           295680    \n",
      "_________________________________________________________________\n",
      "attention_4 (Attention)      (None, 256)               301       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 60,856,671\n",
      "Trainable params: 658,783\n",
      "Non-trainable params: 60,197,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_han=get_han(Config.sentence_num, Config.sentence_word_length, word_embed_weight)\n",
    "model_han.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-31T01:40:28.101Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 736/1546 [=============>................] - ETA: 2:33 - loss: 0.6697 - acc: 0.6110"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i == 3:\n",
    "        K.set_value(model_han.optimizer.lr, 0.0002)\n",
    "    if i == 7:\n",
    "        for l in model_han.layers:\n",
    "            l.trainable = True\n",
    "    model_han.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_han.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-31T01:41:40.339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_generator = word_han_train_batch_generator\n",
    "model_hcnn = get_hcnn(Config.sentence_num, Config.sentence_word_length, word_embed_weight)\n",
    "model_hcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-31T01:41:41.339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        K.set_value(model_hcnn.optimizer.lr, 0.0001)\n",
    "    if i == 8:\n",
    "        for l in model_hcnn.layers:\n",
    "            l.trainable = True\n",
    "    model_hcnn.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_hcnn.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch to SPcut embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-31T01:41:42.971Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_word_embed_weight = np.load(Config.word_embed_weight_path_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_generator = word_cnn_train_batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-31T01:41:43.813Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=get_textcnn(Config.word_seq_maxlen, sp_word_embed_weight)\n",
    "for i in range(10):\n",
    "    if i == 4:\n",
    "        K.set_value(model.optimizer.lr, 0.0001)\n",
    "    if i == 7:\n",
    "        for l in model.layers:\n",
    "            l.trainable = True\n",
    "    model.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:07:48.843944Z",
     "start_time": "2018-07-31T01:00:39.765Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_han=get_han(Config.sentence_num, Config.sentence_word_length, word_embed_weight)\n",
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        K.set_value(model_han.optimizer.lr, 0.0001)\n",
    "    if i == 8:\n",
    "        for l in model_han.layers:\n",
    "            l.trainable = True\n",
    "    model_han.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_han.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T01:07:48.847085Z",
     "start_time": "2018-07-31T01:00:40.780Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_hcnn = get_hcnn(Config.word_seq_maxlen, sp_word_embed_weight)\n",
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        K.set_value(model_hcnn.optimizer.lr, 0.0001)\n",
    "    if i == 8:\n",
    "        for l in model_hcnn.layers:\n",
    "            l.trainable = True\n",
    "    model_hcnn.fit_generator(train_batch_generator(train.content.values, train.label.values, batch_size=batch_size),\n",
    "                       epochs=1, steps_per_epoch=train.shape[0]//batch_size,\n",
    "                       validation_data = (val_word_seq, val_label))\n",
    "    pred = np.squeeze(model_hcnn.predict(val_word_seq))\n",
    "    pre, rec, f1 = score(pred, val_label)\n",
    "    print(pre, rec, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "614px",
    "left": "1548px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
